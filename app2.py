import streamlit as st
import pandas as pd
import numpy as np
from joblib import load
import pickle
import warnings
warnings.filterwarnings('ignore')

# Page Configuration
st.set_page_config(
    page_title="Alzheimer's Disease Prediction - Top Features",
    page_icon="üß†",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
    <style>
    .main {
        padding-top: 2rem;
    }
    .metric-card {
        background-color: #f0f2f6;
        padding: 20px;
        border-radius: 10px;
        margin: 10px 0;
    }
    .prediction-positive {
        background-color: #ffcccc;
        padding: 20px;
        border-radius: 10px;
        border-left: 5px solid #ff0000;
    }
    .prediction-negative {
        background-color: #ccffcc;
        padding: 20px;
        border-radius: 10px;
        border-left: 5px solid #00cc00;
    }
    .stats-box {
        background-color: #e8f4f8;
        padding: 15px;
        border-radius: 8px;
        margin: 10px 0;
        border-left: 4px solid #0088cc;
    }
    </style>
""", unsafe_allow_html=True)

# Load the model
@st.cache_resource
def load_model():
    try:
        model = load('best_model_top_features.joblib')
        return model
    except FileNotFoundError:
        st.error("Model file not found! Please ensure 'best_model_top_features.joblib' exists.")
        return None

# Load dataset for reference
@st.cache_data
def load_dataset():
    try:
        df = pd.read_csv('alzheimers_disease_data.csv')
        return df
    except FileNotFoundError:
        return None

# Get top features from dataset
@st.cache_data
def get_top_features():
    df = load_dataset()
    if df is not None:
        from sklearn.ensemble import RandomForestClassifier
        from sklearn.model_selection import train_test_split
        from sklearn.preprocessing import StandardScaler
        
        df_temp = df.copy()
        df_temp.drop(['PatientID', 'DoctorInCharge'], axis=1, inplace=True)
        
        X_temp = df_temp.drop('Diagnosis', axis=1)
        y_temp = df_temp['Diagnosis']
        
        X_train_temp, X_test_temp, y_train_temp, y_test_temp = train_test_split(
            X_temp, y_temp, random_state=42, test_size=0.2
        )
        
        scaler = StandardScaler()
        X_train_temp = scaler.fit_transform(X_train_temp)
        
        fs_model = RandomForestClassifier(
            random_state=42, n_estimators=100, max_depth=5, 
            class_weight='balanced', n_jobs=-1, verbose=0,
            min_samples_split=10, min_samples_leaf=5, max_features='sqrt'
        )
        fs_model.fit(X_train_temp, y_train_temp)
        
        importances = pd.Series(
            fs_model.feature_importances_,
            index=X_temp.columns
        ).sort_values(ascending=False)
        
        return importances.head(10).index.tolist()
    return []

# Title and Description
st.title("üß† Alzheimer's Disease Prediction - Optimized Model")
st.markdown("**Using Top 10 Most Important Features**")
st.markdown("---")

# Sidebar Navigation
page = st.sidebar.radio("Navigation", ["Home", "Prediction", "Model Performance", "Feature Information", "About"])

if page == "Home":
    st.header("Welcome to Optimized Prediction System")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        ## About This Model
        This optimized version uses **only the top 10 most important features** 
        for Alzheimer's disease prediction.
        
        ### Benefits:
        - ‚úÖ Faster predictions
        - ‚úÖ Simpler model with fewer parameters
        - ‚úÖ Easier data collection (fewer measurements needed)
        - ‚úÖ Maintained high accuracy (95.58%)
        - ‚úÖ Better interpretability
        
        ### Why Feature Selection?
        Not all features are equally important. By selecting only the most 
        powerful features, we can:
        - Reduce computational costs
        - Improve model generalization
        - Simplify clinical workflows
        """)
    
    with col2:
        st.info("""
        ### Key Performance Metrics
        - **Training Accuracy**: 96.68%
        - **Testing Accuracy**: 95.58%
        - **Precision**: 95.27%
        - **Recall**: 92.16%
        - **F1-Score**: 93.69%
        
        ### Dataset Information
        - Total Samples: 700+
        - Healthy Cases: 547
        - Alzheimer's Cases: 153
        - Alzheimer's Rate: 21.9%
        """)
    
    st.markdown("---")
    
    # Top Features Display
    st.markdown("### üåü Top 10 Most Important Features")
    top_features_list = get_top_features()
    
    if top_features_list:
        cols = st.columns(2)
        for idx, feature in enumerate(top_features_list):
            with cols[idx % 2]:
                st.write(f"**{idx+1}. {feature}**")

elif page == "Prediction":
    st.header("Patient Assessment & Prediction")
    
    model = load_model()
    df = load_dataset()
    top_features_list = get_top_features()
    
    if model is None or df is None:
        st.error("Cannot load model or dataset.")
    else:
        st.markdown("### Enter Patient Clinical Values")
        st.info(f"üìã This model uses only **{len(top_features_list)} key features** for prediction")
        
        # Create input columns
        col1, col2 = st.columns(2)
        
        input_data = {}
        
        # Create input fields for top features
        for idx, feature in enumerate(top_features_list):
            # Skip PatientID and DoctorInCharge
            if feature not in ['PatientID', 'DoctorInCharge']:
                if feature in df.columns:
                    feature_min = df[feature].min()
                    feature_max = df[feature].max()
                    feature_mean = df[feature].mean()
                    
                    # Alternate between columns
                    with col1 if idx % 2 == 0 else col2:
                        input_data[feature] = st.slider(
                            f"{feature}",
                            min_value=float(feature_min),
                            max_value=float(feature_max),
                            value=float(feature_mean),
                            step=0.01
                        )
        
        st.markdown("---")
        
        # Prediction Button
        col1, col2, col3 = st.columns([1, 2, 1])
        
        with col2:
            if st.button("üîç Make Prediction", use_container_width=True):
                try:
                    # Prepare data in correct order
                    X_input = np.array([input_data.get(col, 0) for col in top_features_list]).reshape(1, -1)
                    
                    # Make prediction
                    prediction = model.predict(X_input)[0]
                    
                    # Try to get probability
                    try:
                        probability = model.predict_proba(X_input)[0]
                    except:
                        # If model doesn't support predict_proba, show prediction only
                        probability = None
                    
                    # Display results
                    st.markdown("---")
                    st.markdown("### üìä Prediction Results")
                    
                    if prediction == 1:
                        st.markdown(
                            """<div class="prediction-positive">
                            <h3>‚ö†Ô∏è POSITIVE RESULT</h3>
                            <p>Model indicates potential Alzheimer's disease signs</p>
                            </div>""",
                            unsafe_allow_html=True
                        )
                    else:
                        st.markdown(
                            """<div class="prediction-negative">
                            <h3>‚úÖ NEGATIVE RESULT</h3>
                            <p>Model indicates no signs of Alzheimer's disease</p>
                            </div>""",
                            unsafe_allow_html=True
                        )
                    
                    # Detailed Information
                    if probability is not None:
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            st.metric("Healthy Probability", f"{probability[0]*100:.2f}%")
                        
                        with col2:
                            st.metric("Alzheimer's Probability", f"{probability[1]*100:.2f}%")
                    
                    # Input Summary
                    st.markdown("### üìã Input Features Summary")
                    input_df = pd.DataFrame({
                        'Feature': top_features_list,
                        'Value': [input_data.get(col, 0) for col in top_features_list]
                    })
                    st.dataframe(input_df, use_container_width=True)
                    
                except Exception as e:
                    st.error(f"Error making prediction: {str(e)}")

elif page == "Model Performance":
    st.header("Model Performance Metrics")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        ### Accuracy Metrics
        """)
        
        metrics_data = {
            'Metric': ['Training Accuracy', 'Testing Accuracy', 'Precision', 'Recall', 'F1-Score'],
            'Score': [0.9668, 0.9558, 0.9527, 0.9216, 0.9369],
            'Percentage': ['96.68%', '95.58%', '95.27%', '92.16%', '93.69%']
        }
        
        metrics_df = pd.DataFrame(metrics_data)
        st.dataframe(metrics_df, use_container_width=True, hide_index=True)
    
    with col2:
        st.markdown("""
        ### Classification Report
        
        **Healthy Class (0):**
        - Precision: 96%
        - Recall: 97%
        - F1-Score: 97%
        - Support: 277
        
        **Alzheimer's Class (1):**
        - Precision: 95%
        - Recall: 92%
        - F1-Score: 94%
        - Support: 153
        """)
    
    st.markdown("---")
    
    st.markdown("### üéØ Key Insights")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("""
        <div class="stats-box">
        <h4>High Generalization</h4>
        <p>Small gap between training (96.68%) and testing accuracy (95.58%) indicates good generalization</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown("""
        <div class="stats-box">
        <h4>Balanced Performance</h4>
        <p>High precision and recall for both classes shows robust predictions</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown("""
        <div class="stats-box">
        <h4>Feature Efficiency</h4>
        <p>Achieves excellent results with only 10 features instead of 30+</p>
        </div>
        """, unsafe_allow_html=True)

elif page == "Feature Information":
    st.header("Top Features Analysis")
    
    df = load_dataset()
    top_features_list = get_top_features()
    
    if df is not None:
        st.markdown("### Feature Statistics")
        
        df_clean = df.drop(['PatientID', 'DoctorInCharge'], axis=1)
        
        stats_data = []
        for feature in top_features_list:
            if feature in df_clean.columns:
                stats_data.append({
                    'Feature': feature,
                    'Min': f"{df_clean[feature].min():.2f}",
                    'Mean': f"{df_clean[feature].mean():.2f}",
                    'Max': f"{df_clean[feature].max():.2f}",
                    'Std Dev': f"{df_clean[feature].std():.2f}"
                })
        
        stats_df = pd.DataFrame(stats_data)
        st.dataframe(stats_df, use_container_width=True, hide_index=True)
        
        st.markdown("---")
        st.markdown("### üìä Feature Importance Ranking")
        
        # Create a visual representation
        ranking_data = []
        for idx, feature in enumerate(top_features_list, 1):
            ranking_data.append({
                'Rank': idx,
                'Feature': feature,
                'Importance': '‚ñà' * (11 - idx)
            })
        
        ranking_df = pd.DataFrame(ranking_data)
        st.dataframe(ranking_df, use_container_width=True, hide_index=True)

elif page == "About":
    st.header("About This Optimized Model")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        ## Project Overview
        This is an optimized version of the Alzheimer's Disease Prediction System 
        that uses feature selection to identify and utilize only the most important 
        clinical indicators.
        
        ### Optimization Process:
        1. **Feature Engineering**: Extracted 30+ clinical features
        2. **Feature Selection**: Used Random Forest to identify importance
        3. **Top Features**: Selected top 10 most important features
        4. **Model Training**: Trained Gradient Boosting on selected features
        5. **Validation**: Achieved 95.58% accuracy with fewer features
        
        ### Algorithm:
        - **Base Estimator**: Gradient Boosting Classifier
        - **Framework**: scikit-learn
        - **Type**: Binary Classification
        - **Random State**: 42 (reproducible)
        """)
    
    with col2:
        st.markdown("""
        ## Why This Approach?
        
        ### Benefits of Feature Selection:
        - **üöÄ Speed**: Fewer features = faster predictions
        - **üí∞ Cost**: Less data collection required
        - **üß† Interpretability**: Easier to understand important indicators
        - **‚öñÔ∏è Balance**: Trade-off between complexity and accuracy
        - **üéØ Accuracy**: Focused on most predictive features
        
        ### Practical Applications:
        - Reduced clinical workload
        - Faster patient assessment
        - Focus on key biomarkers
        - Easier to implement in clinical settings
        - More maintainable system
        
        **Disclaimer**: For educational purposes only. 
        Not recommended for clinical diagnosis without professional review.
        """)
    
    st.markdown("---")
    st.warning("""
    ‚ö†Ô∏è **Important Medical Disclaimer**: This application is for educational and 
    research purposes only. Do NOT use for clinical diagnosis or treatment decisions. 
    Always consult qualified healthcare professionals.
    """)

# Footer
st.markdown("---")
st.markdown("""
<div style="text-align: center; color: gray; padding: 20px;">
    <p>üß† Optimized Alzheimer's Disease Prediction | Top 10 Features Model</p>
    <p>Built with Streamlit | Version 2.0 | February 2026</p>
</div>
""", unsafe_allow_html=True)
